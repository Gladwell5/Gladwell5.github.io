Title: ML Craze
Date: 2023-05-25 18:45
Category: Post

Transformers are the underlying technical reason but for me, alignment/accessibility and economics are also part of the answer.

Training models is very expensive and time-consuming and we weren't totally sure how well it would work to keep doing what we'd been doing. OpenAI pushed ahead with this idea of bigger and bigger models and spent millions on it and eventually trained GPT-3, which was surprisingly good at generating text compared to earlier models. Once they proved that approach worked, everyone else knew it too and they could be more sure that they would have something to show for their money. That's the economic bit.

The alignment bit is that OpenAI did a whole additional training process (with humans in the loop) on GPT-3 to turn it into ChatGPT. GPT-3 could do one thing - generate follow-on text from a starting prompt. With ChatGPT, we saw that prompts could be anything - questions, instructions, etc. and the model can be adjusted to generate in a way that responds to the prompt (rather than just continue on). This made certain language understanding/processing/generation tasks massively more accessible.

With a large instructable general model, the user gets to decide (at prompt time) what they want to do with it instead of needing to pick and train a single smaller model per task in advance. Obviously this depends on the task, typically the more specific a model is, the better it performs.

Basically OpenAI spent the money and effort to prove you could make a model like ChatGPT and they shared the process so anyone could (in theory) do the same. At that point, people could begin looking at ways to make it faster, cheaper and better and they could use GPT (or specific tests) to benchmark the performance and understand more about what matters most in the training process.

TL;DR Once the first really impressive model was made, we were surer about the right process and that knowledge spread fast.